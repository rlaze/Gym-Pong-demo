{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gym-Pong.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "G6M9z-zj0La0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Load pretrained model from Github"
      ]
    },
    {
      "metadata": {
        "id": "r2niS7iJYMo_",
        "colab_type": "code",
        "outputId": "d44111a8-cbbf-4894-8fba-7e288b866b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/rlaze/Gym-Pong-demo/blob/master/saved_model.h5?raw=true\n",
        "!mv 'saved_model.h5?raw=true' saved_model.h5\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-17 19:58:30--  https://github.com/rlaze/Gym-Pong-demo/blob/master/saved_model.h5?raw=true\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/rlaze/Gym-Pong-demo/raw/master/saved_model.h5 [following]\n",
            "--2019-04-17 19:58:30--  https://github.com/rlaze/Gym-Pong-demo/raw/master/saved_model.h5\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rlaze/Gym-Pong-demo/master/saved_model.h5 [following]\n",
            "--2019-04-17 19:58:31--  https://raw.githubusercontent.com/rlaze/Gym-Pong-demo/master/saved_model.h5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5133216 (4.9M) [application/octet-stream]\n",
            "Saving to: ‘saved_model.h5?raw=true’\n",
            "\n",
            "saved_model.h5?raw= 100%[===================>]   4.89M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-04-17 19:58:31 (53.9 MB/s) - ‘saved_model.h5?raw=true’ saved [5133216/5133216]\n",
            "\n",
            "sample_data  saved_model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mfcOun7P2jo9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Processing images and rewards"
      ]
    },
    {
      "metadata": {
        "id": "Zf1qGqWrXXYh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# functions used by Karpathy, see README for link\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# preprocessing\n",
        "def prepro(I):\n",
        "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
        "  I = I[35:195] # crop\n",
        "  I = I[::2,::2,0] # downsample by factor of 2\n",
        "  I[I == 144] = 0 # erase background (background type 1)\n",
        "  I[I == 109] = 0 # erase background (background type 2)\n",
        "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "  return I.astype(np.float).ravel()\n",
        "\n",
        "# reward discount\n",
        "def discount_rewards(r, gamma):\n",
        "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "  r = np.array(r)\n",
        "  discounted_r = np.zeros_like(r)\n",
        "  running_add = 0\n",
        "  # we go from last reward to first one so we don't have to do exponentiations\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    if r[t] != 0: running_add = 0 # if the game ended (in Pong), reset the reward sum\n",
        "    running_add = running_add * gamma + r[t] # the point here is to use Horner's method to compute those rewards efficiently\n",
        "    discounted_r[t] = running_add\n",
        "  discounted_r -= np.mean(discounted_r) #normalizing the result\n",
        "  discounted_r /= np.std(discounted_r) #idem\n",
        "  return discounted_r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H5JKfoQl2hYM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Make model"
      ]
    },
    {
      "metadata": {
        "id": "2uWtfOGqXXYo",
        "colab_type": "code",
        "outputId": "d6522969-85ab-4d6f-a0d9-f8e924171ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "# initialize model\n",
        "model = Sequential()\n",
        "\n",
        "# hidden layer takes a pre-processed frame as input, and has 200 units\n",
        "model.add(Dense(units=200,input_dim=80*80, activation='relu', kernel_initializer='glorot_uniform'))\n",
        "\n",
        "# output layer to determine action to take\n",
        "model.add(Dense(units=1, activation='sigmoid', kernel_initializer='RandomNormal'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5YqGxs1y2xkj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load from git file\n",
        "model.load_weights('saved_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PoUHI3s422Vx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Setup Pong environment"
      ]
    },
    {
      "metadata": {
        "id": "khOUKyMZXXYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "# gym initialization\n",
        "env = gym.make(\"Pong-v0\")\n",
        "observation = env.reset()\n",
        "prev_input = None\n",
        "\n",
        "# Macros\n",
        "UP_ACTION = 2\n",
        "DOWN_ACTION = 3\n",
        "\n",
        "# Hyperparameters\n",
        "gamma = 0.99\n",
        "\n",
        "# initialization of variables used in the main loop\n",
        "x_train, y_train, rewards = [],[],[]\n",
        "reward_sum = 0\n",
        "episode_nb = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xyqp1vd63DDv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Train model"
      ]
    },
    {
      "metadata": {
        "id": "iJRjWUO_4YvB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3> Stop training early by clicking the icon next to the cell"
      ]
    },
    {
      "metadata": {
        "id": "3ufsq6A4XXY5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resume = True\n",
        "running_reward = None\n",
        "epochs_before_saving = 10 # change how often the model saves\n",
        "\n",
        "while (True):\n",
        "\n",
        "    # preprocess the observation, set input as difference between images\n",
        "    cur_input = prepro(observation)\n",
        "    x = cur_input - prev_input if prev_input is not None else np.zeros(80 * 80)\n",
        "    prev_input = cur_input\n",
        "    \n",
        "    # forward the policy network and sample action according to the proba distribution\n",
        "    proba = model.predict(np.expand_dims(x, axis=1).T)\n",
        "    action = UP_ACTION if np.random.uniform() < proba else DOWN_ACTION\n",
        "    y = 1 if action == 2 else 0 # 0 and 1 are our labels\n",
        "\n",
        "    # log the input and label to train later\n",
        "    x_train.append(x)\n",
        "    y_train.append(y)\n",
        "\n",
        "    # do one step in our environment\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    rewards.append(reward)\n",
        "    reward_sum += reward\n",
        "    \n",
        "    # end of an episode\n",
        "    if done:\n",
        "        print('At the end of episode', episode_nb, 'the total reward was :', reward_sum)\n",
        "        \n",
        "        # increment episode number\n",
        "        episode_nb += 1\n",
        "        \n",
        "        # training\n",
        "        model.fit(x=np.vstack(x_train), y=np.vstack(y_train), verbose=1, sample_weight=discount_rewards(rewards, gamma))\n",
        "        \n",
        "        # Saving the weights used by our model\n",
        "        if episode_nb % epochs_before_saving == 0:    \n",
        "            model.save_weights('saved_model_epoch' + str(episode_nb) + '.h5')\n",
        "        \n",
        "        # Log the reward\n",
        "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
        "        \n",
        "        # Resetting\n",
        "        x_train, y_train, rewards = [],[],[]\n",
        "        observation = env.reset()\n",
        "        \n",
        "        if(reward_sum > 9): # arbitrary stop point, or the model trains forever - still, very long train time\n",
        "          break\n",
        "        \n",
        "        reward_sum = 0\n",
        "        prev_input = None\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xWODkquSgZ91",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> View results as gif (downloads to computer)"
      ]
    },
    {
      "metadata": {
        "id": "u__sn3oygZQb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Frame list collector\n",
        "frames = []\n",
        "STEPS = 1000\n",
        "\n",
        "# code for the two only actions in Pong\n",
        "UP_ACTION = 2\n",
        "DOWN_ACTION = 3\n",
        "\n",
        "# initializing our environment\n",
        "env = gym.make(\"Pong-v0\")\n",
        "\n",
        "# beginning of an episode\n",
        "observation = env.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-UIZvBNvggGO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run test games - run above cell to clear previous frames\n",
        "for i in range(STEPS):   \n",
        "    \n",
        "    # preprocess the observation, set input as difference between images\n",
        "    cur_input = prepro(observation)\n",
        "    x = cur_input - prev_input if prev_input is not None else np.zeros(80 * 80)\n",
        "    prev_input = cur_input\n",
        "    \n",
        "    # forward the policy network and sample action according to the proba distribution\n",
        "    proba = model.predict(np.expand_dims(x, axis=1).T)\n",
        "    action = UP_ACTION if np.random.uniform() < proba else DOWN_ACTION\n",
        "    y = 1 if action == 2 else 0 # 0 and 1 are our labels\n",
        "\n",
        "    #run one step\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    frames.append(observation) # collecting observation\n",
        "\n",
        "    # if episode is over, reset to beginning\n",
        "    if done:\n",
        "        observation = env.reset()\n",
        "        frames.append(observation) # collecting observation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D24Ls_1Zgi04",
        "colab_type": "code",
        "outputId": "e08fe731-9e34-4f35-9b57-d37f94be833f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "\n",
        "def save_frames_as_gif(frames, filename=None):\n",
        "    \"\"\"\n",
        "    Save a list of frames as a gif\n",
        "    \"\"\"\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
        "    if filename:\n",
        "        anim.save(filename, dpi=72, writer='imagemagick')\n",
        "        \n",
        "# Save the run\n",
        "save_frames_as_gif(frames, filename='pong-model-1000-steps.gif')\n",
        "!ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MovieWriter imagemagick unavailable. Trying to use pillow instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pong-model-1000-steps.gif  sample_data\tsaved_model.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM4AAAD8CAYAAAA/rZtiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA7pJREFUeJzt3cFNG1EUQFFPRAOJa0gHbGCPlIgW\n6CEShaCkB1pAWbCHDR2kBqcFs0PBCshcjZmxOWcFsgxvc/Xnj//AsF6vF8DbfJp6ANhHwoFAOBAI\nBwLhQCAcCIQDgXAgEA4ER1MPsFgsFsMwvHp84ee3z+81Cjz58fvv8NJrswhnjmGcnZ68+T23d/c7\nmGT/PVyev/k9x1c3O5hkPC7VIBAOBMKBYBZ7nH3wv/1L2Qd9RNvsV8o+aEpWHAiEA4FwILDH2ZL9\nTLdv+5dtWHEgEA4EwoHAHmdLPscZz9zPoW3DigOBcCAQDgTCgcDNgS25ETCebT4QnfsNBCsOBMKB\nQDgQDHP4/zi/vn+ZfgjY8NpfubHiQCAcCGZxqbZaraYfAjYsl0uXajAm4UAgHAiEA4FwIBAOBMKB\nQDgQCAeCWZwccMiTOXLIE0YmHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBMKBQDgQCAcC\n4UAgHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBMKB\nQDgQCAcC4UAgHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA4Fw\nIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBMKBQDgQCAcC4UAg\nHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBMKBQDgQ\nCAcC4UAgHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA8HR1AOM5ez05Nn3t3f3E03CR3Aw4cCmi+s/\nT19fX3wd9We7VINAOBAIBwJ7HA7W2Puaf1lxIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBAdz5Mbz\nN7wnKw4EwoFAOBAIB4KDuTnAx/Zwef7s++Orm53+PisOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBMKB\nQDgQCAcC4UAgHAiEA4FwIPAgGwdh1w+ubbLiQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDwbBe\nr6eeYbFaraYfAjYsl8vhpdesOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4E\nwoFgFg+ywb6x4kAgHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiE\nA4FwIBAOBMKBQDgQPALw2k02GuHyowAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MThVg5ba2SZI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Download gif and final model weights\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GoEaG-DvhRaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61bf0d16-b0d4-41d7-c93d-93fcb70c03e9"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "ask = input(\"Do you want to download model and gif? y for yes \")\n",
        "if(ask == 'y'):\n",
        "  files.download('pong-model-1000-steps.gif')\n",
        "  model.save_weights('saved_model.h5')\n",
        "  files.download('saved_model.h5')\n",
        "  print('Downloaded!')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Do you want to download model and gif? y for yes y\n",
            "Downloaded!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}